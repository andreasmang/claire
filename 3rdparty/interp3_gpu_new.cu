/*--------------------------------------------------------------------------*\
Copyright (c) 2008-2010, Danny Ruijters. All rights reserved.
http://www.dannyruijters.nl/cubicinterpolation/
This file is part of CUDA Cubic B-Spline Interpolation (CI).

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:
*  Redistributions of source code must retain the above copyright
   notice, this list of conditions and the following disclaimer.
*  Redistributions in binary form must reproduce the above copyright
   notice, this list of conditions and the following disclaimer in the
   documentation and/or other materials provided with the distribution.
*  Neither the name of the copyright holders nor the names of its
   contributors may be used to endorse or promote products derived from
   this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.

The views and conclusions contained in the software and documentation are
those of the authors and should not be interpreted as representing official
policies, either expressed or implied.

When using this code in a scientific project, please cite one or all of the
following papers:
*  Daniel Ruijters and Philippe Th√©venaz,
   GPU Prefilter for Accurate Cubic B-Spline Interpolation, 
   The Computer Journal, vol. 55, no. 1, pp. 15-20, January 2012.
   http://dannyruijters.nl/docs/cudaPrefilter3.pdf
*  Daniel Ruijters, Bart M. ter Haar Romeny, and Paul Suetens,
   Efficient GPU-Based Texture Interpolation using Uniform B-Splines,
   Journal of Graphics Tools, vol. 13, no. 4, pp. 61-69, 2008.
\*--------------------------------------------------------------------------*/

#include <stdio.h>
#include "petsc.h"
#include "petscconf.h"
#include <cuda.h>
#include <cuda_runtime.h>

#include <thrust/device_vector.h>
#include <thrust/host_vector.h>
#include <thrust/extrema.h>
#include <thrust/pair.h>
#include <algorithm>
#include <thrust/device_ptr.h>

#include <memcpy.cu>
#include <cubicPrefilter3D.cu>
#include <bspline_kernel.cu>
#include <lagrange_kernel.cu>
#include "interp3_gpu_new.hpp"

#include "cuda_helper.hpp"
#include "cuda_profiler_api.h"

#include "zeitgeist.hpp"


#define PI ((double)3.14159265358979323846264338327950288419716939937510)
#define TWO_PI 2.0f*CUDART_PI
#define KERNEL_DIM 4
#define MAX_BLOCKS 1024
#define HALO 7
#define spencil 4
#define lpencil 32
#define sharedrows 64
#define perthreadcomp 8

const int sx = spencil;
const int sy = sharedrows;
const int sxx = lpencil;
const int syy = sharedrows;

// device constants
__constant__ float d_c[HALO+1];
__constant__ int d_nx, d_ny, d_nz;
//__constant__ float d_invnx, d_invny, d_invnz;
//__constant__ float d_invhx, d_invhy, d_invhz;

enum CUBIC_INTERP_TYPE {
    FAST_SPLINE = 0,
    FAST_LAGRANGE = 1,
    SLOW_LAGRANGE = 2,
    SLOW_SPLINE = 3
};


template <typename T>
__host__ __device__
inline T rec3_fmaf(T a, T b, T c, T d, T e, T f) {
    return fmaf(a, b, fmaf(c, d, e*f));
    //return a*b + (c*d + e*f);
}


template <typename T>
__host__ __device__
inline T rec4_fmaf(T a, T b, T c, T d, T e, T f, T g, T h) {
    return fmaf(a, b, fmaf(c, d, fmaf( e, f, g*h)));
}

__global__ void interp0gpu(float* m, float* q1, float* q2, float *q3, float *q, dim3 nx) {
  int i = threadIdx.x + blockIdx.x*blockDim.x;
  int x1 = q1[i];
  int x2 = q2[i];
  int x3 = q3[i];
  q[i] = m[x3 + x2*nx.z + x1*nx.z*nx.y];
}

void interp0(float* m, float* q1, float* q2, float* q3, float* q, int nx[3]) {
  dim3 n(nx[0], nx[1], nx[2]);
  int nl = nx[0]*nx[1]*nx[2];
  interp0gpu<<<nl/256,256>>>(m,q1,q2,q3,q,n);
}


__global__ void printVector(float *m, int n) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i<n) printf("m[%d] = %f\n", i , m[i]);
}

/********************************************************************
 * @brief device function for computing the linear index from given 3D indices
 *******************************************************************/
__device__ inline int getLinearIdx(int i, int j, int k) {
    return i*d_ny*d_nz + j*d_nz + k;
}



/********************************************************************
 * @brief function to add 1 to a an array
 *******************************************************************/
__global__ void load_store(float* f1, float* f2) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    f2[i] = f1[i] + 1;
}



/********************************************************************
 * @brief prefilte for z-direction
 *******************************************************************/
__global__ void prefilter_z(float* dfz, float* f) {
  __shared__ float s_f[sx][sy+2*HALO]; // HALO-wide halo for central diferencing scheme
    
  // note i and k have been exchanged to ac3ount for k being the fastest changing index
  int i   = blockIdx.z;
  int j   = blockIdx.y*blockDim.y + threadIdx.y;
  int k  = blockIdx.x*blockDim.x + threadIdx.x;
  int sk = threadIdx.x + HALO;       // local k for shared memory ac3ess + halo offset
  int sj = threadIdx.y; // local j for shared memory ac3ess

  int globalIdx = getLinearIdx(i,j,k);

  s_f[sj][sk] = f[globalIdx];

  __syncthreads();
    
  int lid,rid;
  // fill in periodic images in shared memory array 
  if (threadIdx.x < HALO) {
    lid = k%d_nz-HALO;
    if (lid<0) lid+=d_nz;
    s_f[sj][sk-HALO] = f[i*d_ny*d_nz + j*d_nz + lid];
    rid = (k+sy)%d_nz;
    s_f[sj][sy+sk] = f[i*d_ny*d_nz + j*d_nz + rid];
  }

  __syncthreads();
    
    dfz[globalIdx] = d_c[0]*s_f[sj][sk];
    for(int l=0; l<HALO; l++) {
        dfz[globalIdx] += d_c[l+1] * (s_f[sj][sk+1+l] + s_f[sj][sk-1-l]);
    }
}


/********************************************************************
 * @brief prefilter for y-direction
 *******************************************************************/
__global__ void prefilter_y(float* dfy, float* f) {
  __shared__ float s_f[syy+2*HALO][sxx]; // HALO-wide halo for central diferencing scheme
    
  // note i and k have been exchanged to ac3ount for k being the fastest changing index
  int i  = blockIdx.z;
  int k  = blockIdx.x*blockDim.x + threadIdx.x;
  int sk = threadIdx.x;       // local k for shared memory ac3ess, fixed
    
    
  for(int j = threadIdx.y; j < syy; j += blockDim.y) {
    int globalIdx = getLinearIdx(i, blockIdx.y*syy + j ,k);
    int sj = j + HALO;
    s_f[sj][sk] = f[globalIdx];
  }

  __syncthreads();

  
  int lid,rid, sj = threadIdx.y + HALO;
  int y = syy*blockIdx.y + threadIdx.y;
  // fill in periodic images in shared memory array 
  if (threadIdx.y < HALO) {
    lid = y%d_ny-HALO;
    if (lid<0) lid+=d_ny;
    s_f[sj-HALO][sk] = f[i*d_ny*d_nz + lid*d_nz + k];
    rid = (y+syy)%d_ny;
    s_f[sj+syy][sk] = f[i*d_ny*d_nz + rid*d_nz + k];
  }

  __syncthreads();
  
  for(int j = threadIdx.y; j < syy; j += blockDim.y) {
    int globalIdx = getLinearIdx(i, blockIdx.y*syy + j ,k);
    int sj = j + HALO;
    dfy[globalIdx] = d_c[0]*s_f[sj][sk];
    for( int l=0; l<HALO; l++) {
        dfy[globalIdx] += d_c[l+1] * ( s_f[sj+1+l][sk] + s_f[sj-1-l][sk]);
    }
  }

}


/********************************************************************
 * @brief prefilter for x-direction
 *******************************************************************/
__global__ void prefilter_x(float* dfx, float* f) {
  __shared__ float s_f[syy+2*HALO][sxx]; // HALO-wide halo for central diferencing scheme
    
  // note i and k have been exchanged to ac3ount for k being the fastest changing index
  int j  = blockIdx.z;
  int k  = blockIdx.x*blockDim.x + threadIdx.x;
  int sk = threadIdx.x;       // local k for shared memory ac3ess, fixed
    
    
  for(int i = threadIdx.y; i < syy; i += blockDim.y) {
    int globalIdx = getLinearIdx(blockIdx.y*syy + i, j ,k);
    int si = i + HALO;
    s_f[si][sk] = f[globalIdx];
  }

  __syncthreads();

  
  int lid,rid, si = threadIdx.y + HALO;
  int x = syy*blockIdx.y + threadIdx.y;
  // fill in periodic images in shared memory array 
  if (threadIdx.y < HALO) {
    lid = x%d_nx-HALO;
    if (lid<0) lid+=d_nx;
    s_f[si-HALO][sk] = f[lid*d_ny*d_nz + j*d_nz + k];
    rid = (x+syy)%d_nx;
    s_f[si+syy][sk] = f[rid*d_ny*d_nz + j*d_nz + k];
  }

  __syncthreads();
  
  for(int i = threadIdx.y; i < syy; i += blockDim.y) {
    int globalIdx = getLinearIdx(blockIdx.y*syy + i , j, k);
    int si = i + HALO;
    dfx[globalIdx] = d_c[0]*s_f[si][sk];
    for( int l=0; l<HALO; l++) {
        dfx[globalIdx] += d_c[l+1] * ( s_f[si+1+l][sk] + s_f[si-1-l][sk]);
    }
  }


}
/********************************************************************
 * @brief device function to do the interpolation of a single point using the Fast Lagrange Method
 * @parm[in] tex input data texture used for interpolation
 * @parm[in] coord_grid query coordinate
 * @parm[in] inv_reg_extent inverse of the dimension of the 3D grid (1/nx, 1/ny, 1/nz)
 * @parm[out] interpolated value
 *******************************************************************/
__global__ void cubicTex3DFastLagrange(cudaTextureObject_t tex,
                                        const PetscScalar* xq,
                                        const PetscScalar* yq,
                                        const PetscScalar* zq, 
                                        PetscScalar* yo,
                                        const float3 inv_ext, int nq)
{
    const int tid = blockDim.x * blockIdx.x + threadIdx.x;
    
    if (tid < nq) {
        float3 coord_grid = make_float3(zq[tid], yq[tid], xq[tid]);
        const float3 index = floor(coord_grid);
        float3 w0, w1, w2, w3;
        lagrange_weights(coord_grid - index, w0, w1, w2, w3);
        
        // compute the locations for the trilinear, bilinear and linear interps
        const float3 g0 = w1 + w2;
        const float3 h0 = (w2/g0 + index + 0.5f)*inv_ext;
        const float idx[2] = { (index.x-0.5f)*inv_ext.x, (index.x+2.5f)*inv_ext.x};
        const float idy[2] = { (index.y-0.5f)*inv_ext.y, (index.y+2.5f)*inv_ext.y};
        const float idz[2] = { (index.z-0.5f)*inv_ext.z, (index.z+2.5f)*inv_ext.z};

        
        /////////////////////// slice 1 ////////////////////////////////////////
        // x weighting
        float Z0,Z2;
        //float row0,row1,row2;
        float point0 = tex3D<float>( tex, idx[0], idy[0], idz[0]); // tex000
        float point1 = tex3D<float>( tex, idx[1], idy[0], idz[0]); // tex100
        float lin0 = tex3D<float>( tex, h0.x, idy[0], idz[0]); // y0z0
        // (w0.x * tex000) + (g0.x * y0z0) + (w3.x * tex100)
        Z0 = w0.y*rec3_fmaf( w0.x,  point0,  g0.x,  lin0,  w3.x,  point1);
        
        point0 = tex3D<float>( tex, idx[0], idy[1], idz[0]); // tex010
        point1 = tex3D<float>( tex, idx[1], idy[1], idz[0]); // tex110
        lin0 = tex3D<float>( tex, h0.x, idy[1], idz[0]); // y1z0
        // (w0.x * tex010) + (g0.x * y1z0) + (w3.x * tex110)
        Z0 = fmaf(w3.y, rec3_fmaf( w0.x,  point0,  g0.x,  lin0,  w3.x,  point1), Z0);

        lin0 = tex3D<float>( tex, idx[0], h0.y, idz[0]); // x0z0
        float lin1 = tex3D<float>( tex, idx[1], h0.y, idz[0]); // x1z0
        float bi0 = tex3D<float>( tex, h0.x, h0.y, idz[0]); // z0
        // (w0.x * x0z0) + (g0.x * z0) + (w3.x * x1z0)
        Z0 = fmaf(g0.y, rec3_fmaf( w0.x,  lin0,    g0.x,  bi0,    w3.x,  lin1), Z0); 
        
        ////////////////////////////////////////// slice 3 //////////////////////////////////////////////////////////
        // x weighting
        point0 = tex3D<float>( tex, idx[0], idy[0], idz[1]); // tex001
        point1 = tex3D<float>( tex, idx[1], idy[0], idz[1]); // tex101
        lin0 = tex3D<float>( tex, h0.x, idy[0], idz[1]); // y0z1
        // (w0.x * tex001) + (g0.x * y0z1) + (w3.x * tex101)
        Z2 = w0.y * rec3_fmaf( w0.x, point0, g0.x, lin0, w3.x, point1);

        point0 = tex3D<float>( tex, idx[0], idy[1], idz[1]); // tex011
        point1 = tex3D<float>( tex, idx[1], idy[1], idz[1]); // tex111
        lin0 = tex3D<float>( tex, h0.x, idy[1], idz[1]); // y1z1
        // (w0.x * tex011) + (g0.x * y1z1) + (w3.x * tex111)
        Z2 = fmaf(w3.y, rec3_fmaf( w0.x, point0, g0.x, lin0,  w3.x, point1), Z2);

        lin0 = tex3D<float>( tex, idx[0], h0.y, idz[1]); // x0z1
        lin1 = tex3D<float>( tex, idx[1], h0.y, idz[1]); // x1z1
        bi0 = tex3D<float>( tex, h0.x, h0.y, idz[1]); // z1
        // (w0.x * x0z1) + (g0.x * z1) + (w3.x * x1z1);
        Z2 = fmaf(g0.y, rec3_fmaf( w0.x, lin0,   g0.x, bi0,   w3.x, lin1), Z2);
        Z2 = fmaf(w0.z, Z0, w3.z*Z2);

        //////////////////////////////////////////////////// slice 2 ////////////////////////////////////////////////
        // single trilinear lookup
        lin0 = tex3D<float>( tex, idx[0], idy[0], h0.z); // x0y0
        lin1 = tex3D<float>( tex, idx[1], idy[0], h0.z); // x1y0
        bi0 = tex3D<float>( tex, h0.x, idy[0], h0.z); // y0
        // (w0.x * x0y0) + (g0.x * y0) + (w3.x * x1y0)
        Z0 = w0.y* rec3_fmaf( w0.x, lin0, g0.x, bi0, w3.x, lin1);

        bi0 = tex3D<float>( tex, idx[0], h0.y, h0.z); // x0
        float bi1 = tex3D<float>( tex, idx[1], h0.y, h0.z); // x1
        float core = tex3D<float>( tex, h0.x, h0.y, h0.z); // core
        // (w0.x * x0) + (g0.x * core) + (w3.x * x1)
        Z0 = fmaf(g0.y, rec3_fmaf( w0.x, bi0, g0.x, core, w3.x, bi1), Z0);


        lin0 = tex3D<float>( tex, idx[0], idy[1], h0.z); // x0y1
        lin1 = tex3D<float>( tex, idx[1], idy[1], h0.z); // x1y1
        bi0 = tex3D<float>( tex, h0.x, idy[1], h0.z); // y1
        // (w0.x * x0y1) + (g0.x * y1) + (w3.x * x1y1)
        Z0 = fmaf(w3.y, rec3_fmaf( w0.x, lin0, g0.x, bi0, w3.x, lin1), Z0);
        yo[tid] = fmaf(g0.z, Z0, Z2);
    }
}

/********************************************************************
 * Fixed departure point
 * @brief device function to do the interpolation of a single point using the Vanilla Lagrange Method
 * @parm[in] tex input data texture used for interpolation
 * @parm[in] coord_grid query coordinate
 * @parm[in] inv_reg_extent inverse of the dimension of the 3D grid (1/nx, 1/ny, 1/nz)
 * @parm[out] interpolated value
 *******************************************************************/
__global__ void fixedpointLagrange(PetscScalar* f, 
                                   const PetscScalar* xq, 
                                   const PetscScalar* yq, 
                                   const PetscScalar* zq,
                                   PetscScalar* fq, 
                                   const float3 inv_ext) {
    const int tid = blockDim.x * blockIdx.x + threadIdx.x;
    const float3 qcoord = make_float3(zq[tid], yq[tid], xq[tid]);
	__shared__ float fs[64];
	const float3 index = floor(qcoord);
	const float3 fraction = qcoord - index;
	float3 w0, w1, w2, w3;
	lagrange_weights(fraction, w0, w1, w2, w3);
    
    float wx[KERNEL_DIM] = {w0.x, w1.x, w2.x, w3.x};
    float wy[KERNEL_DIM] = {w0.y, w1.y, w2.y, w3.y};
    float wz[KERNEL_DIM] = {w0.z, w1.z, w2.z, w3.z};
    
    if (threadIdx.x == 0) {
        PetscScalar *fp = &f[9 + d_nz*9 + d_ny*d_nz*9];
    // indices for the source points to be loaded in Shared Memory
        for (int k=0; k<KERNEL_DIM; k++) 
            for (int j=0; j<KERNEL_DIM; j++) 
                for (int i=0; i<KERNEL_DIM; i++) 
                    fs[k + j*4 + i*16] = fp[k + j*4 + i*16];
    }

    __syncthreads();
    
    float sk,sj,temp=0;
    // computation begins
    for (int k=0; k<KERNEL_DIM; k++) {
        sk = 0;
        for (int j=0; j<KERNEL_DIM; j++)  {
           sj = wx[0]*fs[k + j*4 + 0] +
                wx[1]*fs[k + j*4 + 1*16] + 
                wx[2]*fs[k + j*4 + 2*16] + 
                wx[3]*fs[k + j*4 + 3*16];
           sk = fmaf(wy[j], sj, sk);
        }
        temp = fmaf(wz[k], sk, temp);
    }
   fq[tid] = temp; 
}

/********************************************************************
 * @brief device function to do the interpolation of a single point using the Vanilla Lagrange Method
 * @parm[in] tex input data texture used for interpolation
 * @parm[in] coord_grid query coordinate
 * @parm[in] inv_reg_extent inverse of the dimension of the 3D grid (1/nx, 1/ny, 1/nz)
 * @parm[out] interpolated value
 *******************************************************************/
__global__ void cubicTex3DSlowLagrange(cudaTextureObject_t tex,
                                        const PetscScalar* xq,
                                        const PetscScalar* yq,
                                        const PetscScalar* zq, 
                                        PetscScalar* yo,
                                        const float3 inv_ext, int nq)
{
    const int tid = blockDim.x * blockIdx.x + threadIdx.x;
    
    if (tid < nq) {
        float3 coord_grid = make_float3(zq[tid], yq[tid], xq[tid]);
        const float3 index = floor(coord_grid);
        const float3 fraction = coord_grid - index;
        float3 w0, w1, w2, w3;
        lagrange_weights(fraction, w0, w1, w2, w3);

        float idx[KERNEL_DIM] = { (index.x-0.5f)*inv_ext.x, 
                        (index.x+0.5f)*inv_ext.x,
                        (index.x+1.5f)*inv_ext.x,
                        (index.x+2.5f)*inv_ext.x};
        
        float wx[KERNEL_DIM] = {w0.x, w1.x, w2.x, w3.x};

        float idy[KERNEL_DIM] = { (index.y-0.5f)*inv_ext.y, 
                        (index.y+0.5f)*inv_ext.y,
                        (index.y+1.5f)*inv_ext.y,
                        (index.y+2.5f)*inv_ext.y};
        float wy[KERNEL_DIM] = {w0.y, w1.y, w2.y, w3.y};

        float idz[KERNEL_DIM] = { (index.z-0.5f)*inv_ext.z, 
                        (index.z+0.5f)*inv_ext.z,
                        (index.z+1.5f)*inv_ext.z,
                        (index.z+2.5f)*inv_ext.z};
        float wz[KERNEL_DIM] = {w0.z, w1.z, w2.z, w3.z};
        
        float res = 0;
        int j,k;
        float sj,sk;
        
        for(k=0; k<KERNEL_DIM; k++){
            sk = 0;
#pragma unroll
            for(j=0; j<KERNEL_DIM; j++){
                sj = rec4_fmaf( wx[0],  tex3D<float>(tex, idx[0], idy[j], idz[k]), 
                                wx[1],  tex3D<float>(tex, idx[1], idy[j], idz[k]),
                                wx[2],  tex3D<float>(tex, idx[2], idy[j], idz[k]),
                                wx[3],  tex3D<float>(tex, idx[3], idy[j], idz[k]));
        
                sk = fmaf(wy[j], sj, sk);
            }
            res = fmaf(wz[k], sk, res);
        }
        yo[tid] = res;
    }
}


/********************************************************************
 * @brief device function to do the interpolation of a single point using the Vanilla Spline Method
 * @parm[in] tex input data texture used for interpolation
 * @parm[in] coord_grid query coordinate
 * @parm[in] inv_reg_extent inverse of the dimension of the 3D grid (1/nx, 1/ny, 1/nz)
 * @parm[out] interpolated value
 *******************************************************************/
__global__ void cubicTex3DSlowSpline(cudaTextureObject_t tex,
                                        const PetscScalar* xq,
                                        const PetscScalar* yq,
                                        const PetscScalar* zq, 
                                        PetscScalar* yo,
                                        const float3 inv_ext, int nq)
{
    const int tid = blockDim.x * blockIdx.x + threadIdx.x;
    
    if (tid < nq) {
        float3 coord_grid = make_float3(zq[tid], yq[tid], xq[tid]);
        // transform the coordinate from [0,extent] to [-0.5, extent-0.5]
        float3 index = floor(coord_grid);
        const float3 fraction = coord_grid - index;
        index = index + 0.5f;  //move from [-0.5, extent-0.5] to [0, extent]
    
        float res = 0;
        for (float z=-1; z < 2.5f; z++)  //range [-1, 2]
        {
            float bsplineZ = bspline(z-fraction.z);
            float w = (index.z + z)*inv_ext.z;
            for (float y=-1; y < 2.5f; y++)
            {
                float bsplineYZ = bspline(y-fraction.y) * bsplineZ;
                float v = (index.y + y)*inv_ext.y;
                for (float x=-1; x < 2.5f; x++)
                {
                    float bsplineXYZ = bspline(x-fraction.x) * bsplineYZ;
                    float u = (index.x + x)*inv_ext.z;
                    res = fmaf(bsplineXYZ , tex3D<float>(tex, u, v, w), res);
                }
            }
        }
        yo[tid] = res;
    } 
}



/********************************************************************
 * @brief device function to do the interpolation of a single point using the Fast Spline Method
 * @parm[in] tex input data texture used for interpolation
 * @parm[in] coord_grid query coordinate
 * @parm[in] inv_reg_extent inverse of the dimension of the 3D grid (1/nx, 1/ny, 1/nz)
 * @parm[out] interpolated value
 *******************************************************************/
__global__ void cubicTex3DFastSpline(cudaTextureObject_t tex,
                                        const PetscScalar* xq,
                                        const PetscScalar* yq,
                                        const PetscScalar* zq, 
                                        PetscScalar* yo,
                                        const float3 inv_ext, int nq)
{
    const int tid = blockDim.x * blockIdx.x + threadIdx.x;
    
    if (tid < nq) {
        float3 coord_grid = make_float3(zq[tid], yq[tid], xq[tid]);
        // shift the coordinate from [0,extent] to [-0.5, extent-0.5]
        const float3 index = floor(coord_grid);
        const float3 fraction = coord_grid - index;
        float3 w0, w1, w2, w3;
        bspline_weights(fraction, w0, w1, w2, w3);

        const float3 g0 = w0 + w1;
        const float3 g1 = 1.0f - g0;
        const float3 h0 = ((w1 / g0) - 0.5f + index)*inv_ext;
        const float3 h1 = ((w3 / g1) + 1.5f + index)*inv_ext;
        

        // fetch the eight linear interpolations
        // weighting and fetching is interleaved for performance and stability reasons
        float tex000 = tex3D<float>(tex, h0.x, h0.y, h0.z);
        float tex100 = tex3D<float>(tex, h1.x, h0.y, h0.z);
        //tex000 = g0.x * tex000 + g1.x * tex100;  //weigh along the x-direction
        tex000 = lerp(tex100, tex000, g0.x);
        
        float tex010 = tex3D<float>(tex, h0.x, h1.y, h0.z);
        float tex110 = tex3D<float>(tex, h1.x, h1.y, h0.z);
        //tex010 = g0.x * tex010 + g1.x * tex110;  //weigh along the x-direction
        tex010 = lerp( tex110, tex010, g0.x);
        //tex000 = g0.y * tex000 + g1.y * tex010;  //weigh along the y-direction
        tex000 = lerp( tex010, tex000, g0.y);
        
        float tex001 = tex3D<float>(tex, h0.x, h0.y, h1.z);
        float tex101 = tex3D<float>(tex, h1.x, h0.y, h1.z);
        //tex001 = g0.x * tex001 + g1.x * tex101;  //weigh along the x-direction
        tex001 = lerp( tex101, tex001, g0.x);
        
        float tex011 = tex3D<float>(tex, h0.x, h1.y, h1.z);
        float tex111 = tex3D<float>(tex, h1.x, h1.y, h1.z);
        //tex011 = g0.x * tex011 + g1.x * tex111;  //weigh along the x-direction
        tex011 = lerp( tex111, tex011, g0.x);
        //tex001 = g0.y * tex001 + g1.y * tex011;  //weigh along the y-direction
        tex001 = lerp( tex011, tex001, g0.y);

        //return (g0.z * tex000 + g1.z * tex001);  //weigh along the z-direction
        yo[tid] = lerp( tex001, tex000, g0.z);
    }
}


__device__ float linTex3D(cudaTextureObject_t tex, const float3 coord_grid, const float3 inv_reg_extent)
{
  const float3 coord = (coord_grid+0.5f)*inv_reg_extent;
  return tex3D<float>(tex, coord.x, coord.y, coord.z);
}

// Fast prefilter for B-Splines
void CubicBSplinePrefilter3D_fast(float *m, int* nx, float *mtemp1, float *mtemp2) {
    
    float time=0, dummy_time=0;
    int repcount = 1;
    cudaEvent_t startEvent, stopEvent;
    cudaEventCreate(&startEvent);
    cudaEventCreate(&stopEvent);

    float h_c[HALO+1];
    h_c[0] = sqrt(3);
    float sum = h_c[0];
    for(int l=1; l<HALO+1; l++) {
        h_c[l] = h_c[l-1]*(sqrt(3) - 2);
        sum += h_c[l]*2;
    }
    for(int l=0; l<HALO; l++) h_c[l] /= sum;
    cudaMemcpyToSymbol(d_c, h_c, sizeof(float)*(HALO+1), 0, cudaMemcpyHostToDevice);
    
    // temporary storage for intermediate results
    //float* mtemp;
    //cudaMalloc((void**) &mtemp, sizeof(float)*nx[0]*nx[1]*nx[2]);

    // Z-Prefilter - WARM UP
    dim3 threadsPerBlock_z(sy, sx, 1);
    dim3 numBlocks_z(nx[2]/sy, nx[1]/sx, nx[0]);
    /*prefilter_z<<<numBlocks_z, threadsPerBlock_z>>>(mtemp,m);
    if ( cudaSuccess != cudaGetLastError())
                printf("Error in running warmup gradz kernel\n");
    cudaCheckKernelError();
    
    // check 1-load, 1-add, 1-store time
    int threads = 256;
    int blocks = nx[2]*nx[1]*nx[0]/threads;
    cudaEventRecord(startEvent,0); 
    load_store<<<blocks, threads>>>(m, mtemp);
    cudaEventRecord(stopEvent,0);
    cudaEventSynchronize(stopEvent);
    cudaEventElapsedTime(&dummy_time, startEvent, stopEvent);
    time+=dummy_time;
    cudaDeviceSynchronize();
    printf("> laod-store avg time = %fmsec\n", time);
    time = 0;*/


    
    // Y-Gradient
    dim3 threadsPerBlock_y(sxx, syy/perthreadcomp, 1);
    dim3 numBlocks_y(nx[2]/sxx, nx[1]/syy, nx[0]);
    
    // X-Gradient
    dim3 threadsPerBlock_x(sxx, syy/perthreadcomp, 1);
    dim3 numBlocks_x(nx[2]/sxx, nx[0]/syy, nx[1]);

    // start recording the interpolation kernel
    //cudaEventRecord(startEvent,0); 
    

    //for (int rep=0; rep<repcount; rep++) { 
        // X
        prefilter_x<<<numBlocks_x, threadsPerBlock_x>>>(mtemp1, m);
        if ( cudaSuccess != cudaGetLastError())
            printf("Error in running gradx kernel\n");
        cudaCheckKernelError();
        // Y 
        prefilter_y<<<numBlocks_y, threadsPerBlock_y>>>(mtemp2, mtemp1);
        if ( cudaSuccess != cudaGetLastError())
            printf("Error in running gradx kernel\n");
        cudaCheckKernelError();
        // Z
        prefilter_z<<<numBlocks_z, threadsPerBlock_z>>>(mtemp1, mtemp2);
        if ( cudaSuccess != cudaGetLastError())
            printf("Error in running gradx kernel\n");
        cudaCheckKernelError();
    //}

    /*cudaEventRecord(stopEvent,0);
    cudaEventSynchronize(stopEvent);
    cudaEventElapsedTime(&dummy_time, startEvent, stopEvent);
    time+=dummy_time;
    cudaDeviceSynchronize();
    cudaEventDestroy(startEvent);
    cudaEventDestroy(stopEvent);*/
    
    //cudaMemcpy((void*)m, (void*)mtemp, sizeof(float)*nx[0]*nx[1]*nx[2], cudaMemcpyDeviceToDevice);
    //if ( cudaSuccess != cudaGetLastError())
    //            printf("Error in copying data\n");
    
    //if ( mtemp != NULL) cudaFree(mtemp);
    
    // print interpolation time and number of interpolations in Mvoxels/sec
    //printf("> prefilter avg eval time = %fmsec\n", time/repcount);
}




/********************************************************************
 * @brief function to create a 3D texture from the given cuda Pitched Pointer denoting volume (3D) data
 *******************************************************************/
extern "C" cudaTextureObject_t initTextureFromVolume(cudaPitchedPtr volume, cudaExtent extent) {
   cudaError_t err = cudaSuccess;
   cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc<float>();
   cudaArray* cuArray;
   err = cudaMalloc3DArray(&cuArray, &channelDesc, extent, 0);
   if (err != cudaSuccess){
        fprintf(stderr, "Failed to allocate 3D cudaArray (error code %s)!\n", cudaGetErrorString(err));
        exit(EXIT_FAILURE);
   }
   
   cudaMemcpy3DParms p = {0};
   p.srcPtr = volume;
   p.dstArray = cuArray;
   p.extent = extent;
   p.kind = cudaMemcpyDeviceToDevice;
   err = cudaMemcpy3D(&p);
   if (err != cudaSuccess){
        fprintf(stderr, "Failed to copy 3D memory to cudaArray (error code %s)!\n", cudaGetErrorString(err));
        exit(EXIT_FAILURE);
   }
    /* create cuda resource description */
    struct cudaResourceDesc resDesc;
    memset( &resDesc, 0, sizeof(resDesc));
    resDesc.resType = cudaResourceTypeArray;
    resDesc.res.array.array = cuArray;

    struct cudaTextureDesc texDesc;
    memset(&texDesc, 0, sizeof(texDesc));
    texDesc.addressMode[0] = cudaAddressModeWrap;
    texDesc.addressMode[1] = cudaAddressModeWrap;
    texDesc.addressMode[2] = cudaAddressModeWrap;
    texDesc.readMode = cudaReadModeElementType;
    texDesc.filterMode = cudaFilterModeLinear;
    texDesc.normalizedCoords = 1;

    cudaTextureObject_t texObj = 0;
    err = cudaCreateTextureObject( &texObj, &resDesc, &texDesc, NULL);
    if (err != cudaSuccess){
        fprintf(stderr, "Failed to create texture (error code %s)!\n", cudaGetErrorString(err));
        exit(EXIT_FAILURE);
    }
    return texObj;
}

/********************************************************************
 * @brief create texture object with empty data (cudaArray)
 *******************************************************************/
extern "C" cudaTextureObject_t gpuInitEmptyTexture(int* nx) {

   cudaError_t err = cudaSuccess;
   cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc<float>();
   cudaExtent extent = make_cudaExtent(nx[2], nx[1], nx[0]);
   cudaArray* cuArray;
   err = cudaMalloc3DArray(&cuArray, &channelDesc, extent, 0);
   if (err != cudaSuccess){
        fprintf(stderr, "Failed to allocate 3D cudaArray (error code %s)!\n", cudaGetErrorString(err));
        exit(EXIT_FAILURE);
   }
    
    /* create cuda resource description */
    struct cudaResourceDesc resDesc;
    memset( &resDesc, 0, sizeof(resDesc));
    resDesc.resType = cudaResourceTypeArray;
    resDesc.res.array.array = cuArray;

    struct cudaTextureDesc texDesc;
    memset(&texDesc, 0, sizeof(texDesc));
    texDesc.addressMode[0] = cudaAddressModeWrap;
    texDesc.addressMode[1] = cudaAddressModeWrap;
    texDesc.addressMode[2] = cudaAddressModeWrap;
    texDesc.readMode = cudaReadModeElementType;
    texDesc.filterMode = cudaFilterModeLinear;
    texDesc.normalizedCoords = 1;

    cudaTextureObject_t texObj = 0;
    err = cudaCreateTextureObject( &texObj, &resDesc, &texDesc, NULL);
    if (err != cudaSuccess){
        fprintf(stderr, "Failed to create texture (error code %s)!\n", cudaGetErrorString(err));
        exit(EXIT_FAILURE);
    }
    return texObj;
}

/********************************************************************************
 * @brief update texture object by copying volume data to 3D cudaArray container
 *******************************************************************************/
void updateTextureFromVolume(cudaPitchedPtr volume, cudaExtent extent, cudaTextureObject_t texObj) {
    cudaError_t err = cudaSuccess;
    cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc<float>();

    /* create cuda resource description */
    struct cudaResourceDesc resDesc;
    memset( &resDesc, 0, sizeof(resDesc));
    cudaGetTextureObjectResourceDesc( &resDesc, texObj);

    cudaMemcpy3DParms p = {0};
    p.srcPtr = volume;
    p.dstArray = resDesc.res.array.array;
    p.extent = extent;
    p.kind = cudaMemcpyDeviceToDevice;
    err = cudaMemcpy3D(&p);
    if (err != cudaSuccess) {
        fprintf(stderr, "Failed to copy 3D memory to cudaArray (error name %s = %s)!\n", cudaGetErrorName(err), cudaGetErrorString(err));
        exit(EXIT_FAILURE);
    }
}


/********************************************************************
 * @brief linear interpolation kernel for scalar field
 * @parm[in] yi_tex 3D texture used for interpolation
 * @parm[in] xq,yq,zq query coordinates
 * @parm[in] nx array denoting number of query coordinates in each dimension 
 * @parm[out] yo memory for storing interpolated values
 *******************************************************************/
__global__ void interp3D_kernel_linear(
        cudaTextureObject_t  yi_tex,
        const PetscScalar* xq,
        const PetscScalar* yq,
        const PetscScalar* zq, 
        PetscScalar* yo,
        const float3 inv_nx, int nq) {
    // Get thread index 
    const int tid = blockDim.x * blockIdx.x + threadIdx.x;
    if (tid < nq) {
      float3 qcoord = make_float3(zq[tid], yq[tid], xq[tid]);
      yo[tid] = linTex3D(yi_tex, qcoord, inv_nx);
    }
}


/********************************************************************
 * @brief host function to do interpolation of a scalar field
 * @parm[in] yi input data values 
 * @parm[in] xq1,yq1,zq1 query coordinates
 * @parm[in] yi_tex texture object
 * @parm[in] nx array denoting number of query coordinates in each dimension 
 * @parm[out] yo interpolated values
 * @parm[out] interp_time time for computing the interpolation
 *******************************************************************/
void gpuInterp3Dkernel(
           PetscScalar* yi,
           const PetscScalar* xq1,
           const PetscScalar* xq2,
           const PetscScalar* xq3,
           PetscScalar* yo,
           float *tmp1, float* tmp2,
           int*  nx,
           cudaTextureObject_t yi_tex,
           int iporder,
           cudaExtent yi_extent,
           const float3 inv_nx,
           long int nq)
{
    // SET cubic interpolation type here
    enum CUBIC_INTERP_TYPE interp_type = FAST_LAGRANGE;
    cudaPitchedPtr yi_cudaPitchedPtr;
    if (iporder == 3) {
      cudaMemcpyToSymbol(d_nx, &nx[0], sizeof(int), 0, cudaMemcpyHostToDevice);
      cudaMemcpyToSymbol(d_ny, &nx[1], sizeof(int), 0, cudaMemcpyHostToDevice);
      cudaMemcpyToSymbol(d_nz, &nx[2], sizeof(int), 0, cudaMemcpyHostToDevice);
      switch (interp_type) {
        case FAST_SPLINE:
            CubicBSplinePrefilter3D_fast(yi, nx, tmp1, tmp2);
            yi_cudaPitchedPtr = make_cudaPitchedPtr(static_cast<void*>(tmp1), nx[2]*sizeof(float), nx[2], nx[1]);
            break;
        case SLOW_SPLINE:
            CubicBSplinePrefilter3D_fast(yi, nx, tmp1, tmp2);
            yi_cudaPitchedPtr = make_cudaPitchedPtr(static_cast<void*>(tmp1), nx[2]*sizeof(float), nx[2], nx[1]);
            break;
        case FAST_LAGRANGE:
            yi_cudaPitchedPtr = make_cudaPitchedPtr(static_cast<void*>(yi), nx[2]*sizeof(float), nx[2], nx[1]);
            break;
        case SLOW_LAGRANGE:
            yi_cudaPitchedPtr = make_cudaPitchedPtr(static_cast<void*>(yi), nx[2]*sizeof(float), nx[2], nx[1]);
            break;
      };

      updateTextureFromVolume(yi_cudaPitchedPtr, yi_extent, yi_tex);
    } else {
      // make input image a cudaPitchedPtr for fi
      yi_cudaPitchedPtr = make_cudaPitchedPtr(static_cast<void*>(yi), nx[2]*sizeof(float), nx[2], nx[1]);
      // update texture object
      updateTextureFromVolume(yi_cudaPitchedPtr, yi_extent, yi_tex);
    }
  
    int threads = 256;
    int blocks = (nq+255)/threads;
    
    // launch the interpolation kernel
    switch (iporder) {
    case 1:
      interp3D_kernel_linear<<<blocks,threads>>>(yi_tex, xq1, xq2, xq3, yo, inv_nx, nq);
      break;
    case 3:
      switch (interp_type) {
        case FAST_SPLINE:
            cubicTex3DFastSpline<<<blocks,threads>>>(yi_tex, xq1, xq2, xq3, yo, inv_nx, nq);
            break;
        case SLOW_SPLINE:
            cubicTex3DSlowSpline<<<blocks,threads>>>(yi_tex, xq1, xq2, xq3, yo, inv_nx, nq);
            break;
        case FAST_LAGRANGE:
            cubicTex3DFastLagrange<<<blocks,threads>>>(yi_tex, xq1, xq2, xq3, yo, inv_nx, nq);
            break;
        case SLOW_LAGRANGE:
            cubicTex3DSlowLagrange<<<blocks,threads>>>(yi_tex, xq1, xq2, xq3, yo, inv_nx, nq);
            break;
      };
      break;
    //default:
      // Not implemented
    };
    //cudaCheckKernelError();
}

/********************************************************************
 * @brief host function to do interpolation of a scalar field
 * @parm[in] yi input data values 
 * @parm[in] xq1,yq1,zq1 query coordinates
 * @parm[in] yi_tex texture object
 * @parm[in] nx array denoting number of query coordinates in each dimension 
 * @parm[out] yo interpolated values
 * @parm[out] interp_time time for computing the interpolation
 *******************************************************************/
void gpuInterp3D(
           PetscScalar* yi,
           const PetscScalar* xq1,
           const PetscScalar* xq2,
           const PetscScalar* xq3,
           PetscScalar* yo,
           float *tmp1, float* tmp2,
           int*  nx,
           long int nq,
           cudaTextureObject_t yi_tex,
           int iporder,
           float* interp_time)
{
   
    // define inv of nx for normalizing in texture interpolation
    const float3 inv_nx = make_float3(  1.0f/static_cast<float>(nx[2]),
                                        1.0f/static_cast<float>(nx[1]), 
                                        1.0f/static_cast<float>(nx[0]));
    
    // create a cudaExtent for input resolution
    cudaExtent yi_extent = make_cudaExtent(nx[2], nx[1], nx[0]);

    gpuInterp3Dkernel(yi,xq1,xq2,xq3,yo,tmp1,tmp2,nx,yi_tex,iporder,yi_extent,inv_nx,nq);
    
    cudaDeviceSynchronize();
}

/********************************************************************
 * @brief host function to do interpolation of a scalar field
 * @parm[in] yi input data values 
 * @parm[in] xq1,yq1,zq1 query coordinates
 * @parm[in] yi_tex texture object
 * @parm[in] nx array denoting number of query coordinates in each dimension  (this will be isize when using multi-GPU)
 * @parm[out] yo interpolated values
 * @parm[out] interp_time time for computing the interpolation
 *******************************************************************/
void gpuInterpVec3D(
           PetscScalar* yi1, PetscScalar* yi2, PetscScalar* yi3,
           const PetscScalar* xq1, const PetscScalar* xq2, const PetscScalar* xq3,
           PetscScalar* yo1, PetscScalar* yo2, PetscScalar* yo3,
           float *tmp1, float* tmp2,
           int*  nx, long int nq, cudaTextureObject_t yi_tex, int iporder, float* interp_time)
{
    // define inv of nx for normalizing in texture interpolation
    const float3 inv_nx = make_float3(  1.0f/static_cast<float>(nx[2]),
                                        1.0f/static_cast<float>(nx[1]), 
                                        1.0f/static_cast<float>(nx[0]));

    // create a cudaExtent for input resolution
    cudaExtent yi_extent = make_cudaExtent(nx[2], nx[1], nx[0]);

    //int threads = 256;
    //int blocks = (nq+255)/threads;
    //printVector<<<blocks, threads>>>(yi1, nq);

    gpuInterp3Dkernel(yi1,xq1,xq2,xq3,yo1,tmp1,tmp2,nx,yi_tex,iporder,yi_extent,inv_nx,nq);
    gpuInterp3Dkernel(yi2,xq1,xq2,xq3,yo2,tmp1,tmp2,nx,yi_tex,iporder,yi_extent,inv_nx,nq);
    gpuInterp3Dkernel(yi3,xq1,xq2,xq3,yo3,tmp1,tmp2,nx,yi_tex,iporder,yi_extent,inv_nx,nq);
    
    cudaDeviceSynchronize();
}

void getMax(ScalarType* x, int nl, ScalarType* max) {
    thrust::device_ptr<ScalarType> x_thrust;
    x_thrust = thrust::device_pointer_cast (x);
    // find the max itr
    thrust::device_vector<ScalarType>::iterator it = thrust::max_element(x_thrust, x_thrust + nl);
    *max = *it;
}
    
/********************************************************************
 * @brief host function to do interpolation of a scalar field
 * @parm[in] yi regular grid values [yix0,yix1,yix2,....,yiy0,yiy1,yiy2,....,yiz0,yiz1,yiz2....]
 * @parm[in] xq query coordinates   [x0,y0,z0,x1,y1,z1,.....]
 * @parm[in] yi_tex texture object 
 * @parm[in] nx array denoting number of query coordinates in each dimension  (this will be isize when using multi-GPU)
 * @parm[out] yo interpolated values (same format at yi)
 *******************************************************************/
/*void gpuInterpVec3D(
           PetscScalar* yi, 
           const PetscScalar* xq,
           PetscScalar* yo,
           float *tmp1, float* tmp2,
           int*  nx, cudaTextureObject_t yi_tex, int iporder, float* interp_time)
{
    // define inv of nx for normalizing in texture interpolation
    const float3 inv_nx = make_float3(  1.0f/static_cast<float>(nx[2]),
                                        1.0f/static_cast<float>(nx[1]), 
                                        1.0f/static_cast<float>(nx[0]));
    long int nq = nx[0]*nx[1]*nx[2]; 
    
    // create a cudaExtent for input resolution
    cudaExtent yi_extent = make_cudaExtent(nx[2], nx[1], nx[0]);
    
    gpuInterp3Dkernel(&yi[0*nq], xq, &yo[0*nq], tmp1, tmp2, nx, yi_tex, iporder, yi_extent, inv_nx, nq);
    gpuInterp3Dkernel(&yi[1*nq], xq, &yo[1*nq], tmp1, tmp2, nx, yi_tex, iporder, yi_extent, inv_nx, nq);
    gpuInterp3Dkernel(&yi[2*nq], xq, &yo[2*nq], tmp1, tmp2, nx, yi_tex, iporder, yi_extent, inv_nx, nq);
    
    cudaDeviceSynchronize();
}
*/

__global__ void normalizeQueryPointsKernel(ScalarType* xq1, ScalarType* xq2, ScalarType* xq3, ScalarType* all_query_points, int nq, const float3 ng, const float3 scale, const float3 offset) {

    int tid = threadIdx.x + blockIdx.x * blockDim.x; 

    if (tid<nq) {
        //xq1[tid] = (all_query_points[tid*3 + 0]*ng.x + offset.x)*scale.x;
        //xq2[tid] = (all_query_points[tid*3 + 1]*ng.y + offset.y)*scale.y;
        //xq3[tid] = (all_query_points[tid*3 + 2]*ng.z + offset.z)*scale.z;
        xq1[tid] = (all_query_points[tid*3 + 0]*ng.x + offset.x);
        xq2[tid] = (all_query_points[tid*3 + 1]*ng.y + offset.y);
        xq3[tid] = (all_query_points[tid*3 + 2]*ng.z + offset.z);
        //printf("tid = %d \t xq = %0.4f \t yq = %0.4f \t zq = %f\n", tid, xq1[tid], xq2[tid], xq3[tid]);
    }

}


void normalizeQueryPoints(ScalarType* xq1, ScalarType* xq2, ScalarType* xq3, ScalarType* all_query_points, int nq, int* isize, int* nx, int* procid, int nghost) {
    
    const float3 scale = make_float3( 1.0f/static_cast<float>(isize[0]+2*nghost), 
                                      1.0f/static_cast<float>(isize[1]+2*nghost),
                                      1.0f/static_cast<float>(isize[2]+2*nghost) );
    
    const float3 offset = make_float3( static_cast<float>(nghost-procid[0]*isize[0]),
                                       static_cast<float>(nghost-procid[1]*isize[1]),
                                       static_cast<float>(nghost));
    
    const float3 ng = make_float3( nx[0], nx[1], nx[2] );

    int threads = 256;
    int blocks = (nq+threads-1)/threads;
    normalizeQueryPointsKernel<<<blocks,threads>>>(xq1, xq2, xq3, all_query_points, nq, ng, scale, offset);

    cudaDeviceSynchronize();
}

